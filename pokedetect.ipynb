{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import sklearn\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage\n",
    "from skimage import transform,util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUCKKKKKKKK\n",
      "FUCKKKKKKKK\n",
      "FUCKKKKKKKK\n",
      "FUCKKKKKKKK\n",
      "FUCKKKKKKKK\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"/PokemonData/\"\n",
    "\n",
    "# array of 149 pokemon's images (list of 149 lists of x# of img arrays)\n",
    "allpoke = []\n",
    "poke_classes = []\n",
    "\n",
    "# for svg images\n",
    "# from cairosvg import svg2png\n",
    "\n",
    "# read in all images to 149 sublists\n",
    "img_count = 0\n",
    "for subdir in sorted(os.listdir(data_dir)):\n",
    "    if subdir == \".DS_Store\":\n",
    "        continue\n",
    "    path = data_dir + subdir + \"/\"\n",
    "    #print(path)\n",
    "    poke_classes.append(subdir)\n",
    "    poke_imgs = []\n",
    "    for image in os.listdir(path):\n",
    "        img = cv2.imread(path+image)\n",
    "        #print(image)\n",
    "        if image.endswith(('.svg', '.DS_Store')): # just skip it for now?\n",
    "            print(\"FUCKKKKKKKK\") \n",
    "            #I = svg2png(url = path+image)\n",
    "            #nparr = np.fromstring(I, np.uint8)\n",
    "            #img = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #convert it to RGB channel\n",
    "        \n",
    "        # normalize color values and resize before adding\n",
    "        norm_img = img/255\n",
    "        resize_img = transform.resize(norm_img,(300,300))\n",
    "        poke_imgs.append(resize_img)\n",
    "        img_count+=1\n",
    "    allpoke.append(poke_imgs)\n",
    "    \n",
    "plt.imshow(allpoke[0][0])\n",
    "plt.colorbar()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_train_test(images, testsize): # return list of image arrays\n",
    "    training_poke = []\n",
    "    testing_poke = []\n",
    "    for i in images:\n",
    "        train_set, test_set = train_test_split(i, test_size=testsize, shuffle=True)\n",
    "        training_poke.append(train_set)\n",
    "        testing_poke.append(test_set)\n",
    "    return training_poke, testing_poke\n",
    "\n",
    "# flip/rotate/distort/blur/noise/resize\n",
    "\n",
    "def aug_set(train_poke):\n",
    "    tot_aug_imgs = 0\n",
    "    aug_train = []\n",
    "    for poke in train_poke:\n",
    "        aug_poke = []\n",
    "        for i in poke:\n",
    "            aug_poke.append(i)\n",
    "            # horiz flip and rotate 45 deg both ways\n",
    "            hflip = np.fliplr(i)\n",
    "            aug_poke.append(hflip)\n",
    "#             counter_rot_hflip = transform.rotate(hflip, angle=45)\n",
    "#             aug_poke.append(counter_rot_hflip)\n",
    "#             rot_hflip = transform.rotate(hflip, angle=-45)\n",
    "#             aug_poke.append(rot_hflip)\n",
    "            # vert flip and rotate 45 deg both ways\n",
    "            vflip = np.flipud(i)\n",
    "            aug_poke.append(vflip)\n",
    "            counter_rot_vflip = transform.rotate(vflip, angle=45)\n",
    "            aug_poke.append(counter_rot_vflip)\n",
    "            rot_vflip = transform.rotate(vflip, angle=-45)\n",
    "            aug_poke.append(rot_vflip)\n",
    "            # noise, blur\n",
    "            noisy = util.random_noise(i)\n",
    "            aug_poke.append(noisy)\n",
    "            blur = cv2.GaussianBlur(i, (11,11),0)\n",
    "            aug_poke.append(blur)\n",
    "            tot_aug_imgs+=9\n",
    "        aug_train.append(aug_poke)\n",
    "    print(tot_aug_imgs)\n",
    "    return aug_train\n",
    "\n",
    "print(\"num of abra images before aug\")\n",
    "print(img_count)\n",
    "train_set, test_set = split_train_test(allpoke, .2)\n",
    "print(\"num of abra images after aug\")\n",
    "aug_train_set = aug_set(train_set)\n",
    "# print(len(train_set[0][0]))\n",
    "\n",
    "# print(len(aug_train_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set[0]))\n",
    "print(len(aug_train_set[0]))\n",
    "\n",
    "imge = aug_train_set[0][:7]\n",
    "for i in imge:\n",
    "    plt.imshow(i)\n",
    "    plt.figure()\n",
    "    \n",
    "\n",
    "for poke in aug_train_set:\n",
    "    poke = [transforms.ToTensor(x) for x in poke]\n",
    "for poke in test_set:\n",
    "    poke = [transforms.ToTensor(x) for x in poke]\n",
    "\n",
    "# Put into a Dataloader using torch library\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size =64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
